{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbb2966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Gemini_BTCUSD_1hr.csv\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c019ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1647226800000</td>\n",
       "      <td>2022-03-14 03:00:00</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>38055.23</td>\n",
       "      <td>38073.96</td>\n",
       "      <td>38023.12</td>\n",
       "      <td>38060.13</td>\n",
       "      <td>0.868827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1647223200000</td>\n",
       "      <td>2022-03-14 02:00:00</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>38076.24</td>\n",
       "      <td>38186.59</td>\n",
       "      <td>38009.17</td>\n",
       "      <td>38055.23</td>\n",
       "      <td>10.429404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1647219600000</td>\n",
       "      <td>2022-03-14 01:00:00</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>37850.60</td>\n",
       "      <td>38348.52</td>\n",
       "      <td>37850.60</td>\n",
       "      <td>38076.24</td>\n",
       "      <td>62.900385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1647216000000</td>\n",
       "      <td>2022-03-14 00:00:00</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>37791.31</td>\n",
       "      <td>37886.84</td>\n",
       "      <td>37578.09</td>\n",
       "      <td>37850.60</td>\n",
       "      <td>45.794943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1647212400000</td>\n",
       "      <td>2022-03-13 23:00:00</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>37748.40</td>\n",
       "      <td>37905.78</td>\n",
       "      <td>37599.00</td>\n",
       "      <td>37791.31</td>\n",
       "      <td>46.112435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unix Timestamp                 Date  Symbol      Open      High       Low  \\\n",
       "0   1647226800000  2022-03-14 03:00:00  BTCUSD  38055.23  38073.96  38023.12   \n",
       "1   1647223200000  2022-03-14 02:00:00  BTCUSD  38076.24  38186.59  38009.17   \n",
       "2   1647219600000  2022-03-14 01:00:00  BTCUSD  37850.60  38348.52  37850.60   \n",
       "3   1647216000000  2022-03-14 00:00:00  BTCUSD  37791.31  37886.84  37578.09   \n",
       "4   1647212400000  2022-03-13 23:00:00  BTCUSD  37748.40  37905.78  37599.00   \n",
       "\n",
       "      Close     Volume  \n",
       "0  38060.13   0.868827  \n",
       "1  38055.23  10.429404  \n",
       "2  38076.24  62.900385  \n",
       "3  37850.60  45.794943  \n",
       "4  37791.31  46.112435  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc14f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450912\n",
      "1647226800000\n",
      "0.5498541056580335\n",
      "0.5541927132572176\n",
      "0.5511388550833726\n",
      "0.5531533238702326\n",
      "0.5511388550833726\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#(max'-min')/(max-min)*(value-max)+max'\n",
    "\n",
    "\n",
    "data = df.to_numpy(na_value=35000)\n",
    "\n",
    "print(data.size)\n",
    "print(data[0][0])\n",
    "max_iter = len(df) \n",
    "for k in range(3, 7):\n",
    "#     if k == 6:\n",
    "#         continue\n",
    "    max_val = -1\n",
    "    min_val = 9999999\n",
    "    for i in range(max_iter):\n",
    "        val = data[i - 1][k]\n",
    "        if val > max_val:\n",
    "            max_val = val\n",
    "        if val < max_val:\n",
    "            min_val = val\n",
    "    for i in range(max_iter):\n",
    "        data[i][k] = float(1/(max_val - min_val) * (data[i][k] - max_val) + 1)\n",
    "    print(data[2][k])\n",
    "    \n",
    "print(data[2][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ecbfa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5529177698665164 0.5528461240180864 0.5531533238702326 ...\n",
      " -1.169728137684345e-06 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "data_c = data[:, 6]\n",
    "print(data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432dfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.delete(data, 0, axis=1)\n",
    "data = np.delete(data, 0, axis=1)\n",
    "data = np.delete(data, 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8b8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bbfc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fafc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.delete(data, 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca6fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5656932481537303 0.5664562577267107 0.5664183133665839 16.11749363]\n",
      "0.5518375390880663\n",
      "[0.5529177698665164 0.5528461240180864 0.5531533238702326 ...\n",
      " -1.169728137684345e-06 0.0 0.0]\n",
      "tensor([ 5.5292e-01,  5.5285e-01,  5.5315e-01,  ..., -1.1697e-06,\n",
      "         0.0000e+00,  0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#print(type(data[2][4]))\n",
    "\n",
    "print(data[10])\n",
    "print(data[1][1])\n",
    "print(data_c)\n",
    "d_t = torch.from_numpy(data.astype(np.float32))\n",
    "d_c = torch.from_numpy(data_c.astype(np.float32))\n",
    "d_c.shape\n",
    "print(d_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9944fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd814f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = d_t.shape[0]\n",
    "n_val = int(.2 * n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples).numpy()\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1eb88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = d_t[train_indices]\n",
    "train_d_c = d_c[train_indices]\n",
    "seq_length = 4\n",
    "val_d = d_t[val_indices]\n",
    "val_d_c = d_c[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "855e57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, features, sequence_length=5):\n",
    "       # self.features = features\n",
    "        #self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y = target\n",
    "        self.X = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start:(i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0:(i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "\n",
    "        return x, self.y[i]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910da96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1124, 0.4954, 0.5425,  ..., 0.1231, 0.6126, 0.2607])\n",
      "tensor(0.1368)\n"
     ]
    }
   ],
   "source": [
    "i = 27\n",
    "sequence_length = 160\n",
    "print(val_d_c)\n",
    "train_dataset = SequenceDataset(\n",
    "    train_d,\n",
    "    target=train_d_c,\n",
    "    features=train_d,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    val_d,\n",
    "    target=val_d_c,\n",
    "    features=val_d,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "X, y = train_dataset[i]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b031402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(99)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e4c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "device = torch.device('cuda:0')\n",
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "\n",
    "        _, (hn, _) = self.lstm(x, (h0.to(device), c0.to(device)))\n",
    "        out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b60def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5 #1e-2 1.37 #1e-3 96 1e-4 94\n",
    "num_hidden_units = 32\n",
    "\n",
    "model = ShallowRegressionLSTM(num_sensors=4, hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e431563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Epoch: 0, Loss: 0.189111\n",
      "Epoch: 1, Loss: 0.082144\n",
      "Epoch: 2, Loss: 0.069110\n",
      "Epoch: 3, Loss: 0.061553\n",
      "Epoch: 4, Loss: 0.057261\n",
      "Epoch: 5, Loss: 0.054867\n",
      "Epoch: 6, Loss: 0.053388\n",
      "Epoch: 7, Loss: 0.050694\n",
      "Epoch: 8, Loss: 0.048815\n",
      "Epoch: 9, Loss: 0.047692\n",
      "Epoch: 10, Loss: 0.046929\n",
      "Epoch: 11, Loss: 0.046301\n",
      "Epoch: 12, Loss: 0.045718\n",
      "Epoch: 13, Loss: 0.045159\n",
      "Epoch: 14, Loss: 0.044561\n",
      "Epoch: 15, Loss: 0.043934\n",
      "Epoch: 16, Loss: 0.043269\n",
      "Epoch: 17, Loss: 0.042595\n",
      "Epoch: 18, Loss: 0.041963\n",
      "Epoch: 19, Loss: 0.041267\n",
      "Epoch: 20, Loss: 0.040427\n",
      "Epoch: 21, Loss: 0.039498\n",
      "Epoch: 22, Loss: 0.038421\n",
      "Epoch: 23, Loss: 0.037218\n",
      "Epoch: 24, Loss: 0.035931\n",
      "Epoch: 25, Loss: 0.034696\n",
      "Epoch: 26, Loss: 0.033484\n",
      "Epoch: 27, Loss: 0.032280\n",
      "Epoch: 28, Loss: 0.031044\n",
      "Epoch: 29, Loss: 0.029739\n",
      "Epoch: 30, Loss: 0.028332\n",
      "Epoch: 31, Loss: 0.026823\n",
      "Epoch: 32, Loss: 0.025146\n",
      "Epoch: 33, Loss: 0.023160\n",
      "Epoch: 34, Loss: 0.021184\n",
      "Epoch: 35, Loss: 0.019548\n",
      "Epoch: 36, Loss: 0.017941\n",
      "Epoch: 37, Loss: 0.016360\n",
      "Epoch: 38, Loss: 0.014781\n",
      "Epoch: 39, Loss: 0.013175\n",
      "Epoch: 40, Loss: 0.011553\n",
      "Epoch: 41, Loss: 0.009978\n",
      "Epoch: 42, Loss: 0.008434\n",
      "Epoch: 43, Loss: 0.006864\n",
      "Epoch: 44, Loss: 0.005491\n",
      "Epoch: 45, Loss: 0.004304\n",
      "Epoch: 46, Loss: 0.003324\n",
      "Epoch: 47, Loss: 0.002553\n",
      "Epoch: 48, Loss: 0.001972\n",
      "Epoch: 49, Loss: 0.001495\n",
      "Epoch: 50, Loss: 0.000987\n",
      "Epoch: 51, Loss: 0.000633\n",
      "Epoch: 52, Loss: 0.000468\n",
      "Epoch: 53, Loss: 0.000358\n",
      "Epoch: 54, Loss: 0.000298\n",
      "Epoch: 55, Loss: 0.000245\n",
      "Epoch: 56, Loss: 0.000198\n",
      "Epoch: 57, Loss: 0.000165\n",
      "Epoch: 58, Loss: 0.000138\n",
      "Epoch: 59, Loss: 0.000118\n",
      "Epoch: 60, Loss: 0.000101\n",
      "Epoch: 61, Loss: 0.000090\n",
      "Epoch: 62, Loss: 0.000080\n",
      "Epoch: 63, Loss: 0.000071\n",
      "Epoch: 64, Loss: 0.000065\n",
      "Epoch: 65, Loss: 0.000058\n",
      "Epoch: 66, Loss: 0.000053\n",
      "Epoch: 67, Loss: 0.000049\n",
      "Epoch: 68, Loss: 0.000045\n",
      "Epoch: 69, Loss: 0.000041\n",
      "Epoch: 70, Loss: 0.000039\n",
      "Epoch: 71, Loss: 0.000036\n",
      "Epoch: 72, Loss: 0.000033\n",
      "Epoch: 73, Loss: 0.000032\n",
      "Epoch: 74, Loss: 0.000030\n",
      "Epoch: 75, Loss: 0.000028\n",
      "Epoch: 76, Loss: 0.000027\n",
      "Epoch: 77, Loss: 0.000025\n",
      "Epoch: 78, Loss: 0.000023\n",
      "Epoch: 79, Loss: 0.000022\n",
      "Epoch: 80, Loss: 0.000021\n",
      "Epoch: 81, Loss: 0.000019\n",
      "Epoch: 82, Loss: 0.000018\n",
      "Epoch: 83, Loss: 0.000017\n",
      "Epoch: 84, Loss: 0.000016\n",
      "Epoch: 85, Loss: 0.000015\n",
      "Epoch: 86, Loss: 0.000015\n",
      "Epoch: 87, Loss: 0.000014\n",
      "Epoch: 88, Loss: 0.000013\n",
      "Epoch: 89, Loss: 0.000013\n",
      "Epoch: 90, Loss: 0.000012\n",
      "Epoch: 91, Loss: 0.000012\n",
      "Epoch: 92, Loss: 0.000012\n",
      "Epoch: 93, Loss: 0.000011\n",
      "Epoch: 94, Loss: 0.000011\n",
      "Epoch: 95, Loss: 0.000011\n",
      "Epoch: 96, Loss: 0.000010\n",
      "Epoch: 97, Loss: 0.000010\n",
      "Epoch: 98, Loss: 0.000010\n",
      "Epoch: 99, Loss: 0.000010\n",
      "Epoch: 100, Loss: 0.000010\n",
      "Epoch: 101, Loss: 0.000009\n",
      "Epoch: 102, Loss: 0.000009\n",
      "Epoch: 103, Loss: 0.000009\n",
      "Epoch: 104, Loss: 0.000009\n",
      "Epoch: 105, Loss: 0.000009\n",
      "Epoch: 106, Loss: 0.000009\n",
      "Epoch: 107, Loss: 0.000008\n",
      "Epoch: 108, Loss: 0.000008\n",
      "Epoch: 109, Loss: 0.000008\n",
      "Epoch: 110, Loss: 0.000008\n",
      "Epoch: 111, Loss: 0.000008\n",
      "Epoch: 112, Loss: 0.000008\n",
      "Epoch: 113, Loss: 0.000008\n",
      "Epoch: 114, Loss: 0.000008\n",
      "Epoch: 115, Loss: 0.000007\n",
      "Epoch: 116, Loss: 0.000007\n",
      "Epoch: 117, Loss: 0.000007\n",
      "Epoch: 118, Loss: 0.000007\n",
      "Epoch: 119, Loss: 0.000007\n",
      "Epoch: 120, Loss: 0.000007\n",
      "Epoch: 121, Loss: 0.000007\n",
      "Epoch: 122, Loss: 0.000007\n",
      "Epoch: 123, Loss: 0.000007\n",
      "Epoch: 124, Loss: 0.000007\n",
      "Epoch: 125, Loss: 0.000007\n",
      "Epoch: 126, Loss: 0.000007\n",
      "Epoch: 127, Loss: 0.000007\n",
      "Epoch: 128, Loss: 0.000007\n",
      "Epoch: 129, Loss: 0.000007\n",
      "Epoch: 130, Loss: 0.000007\n",
      "Epoch: 131, Loss: 0.000007\n",
      "Epoch: 132, Loss: 0.000006\n",
      "Epoch: 133, Loss: 0.000006\n",
      "Epoch: 134, Loss: 0.000006\n",
      "Epoch: 135, Loss: 0.000006\n",
      "Epoch: 136, Loss: 0.000006\n",
      "Epoch: 137, Loss: 0.000006\n",
      "Epoch: 138, Loss: 0.000006\n",
      "Epoch: 139, Loss: 0.000006\n",
      "Epoch: 140, Loss: 0.000006\n",
      "Epoch: 141, Loss: 0.000006\n",
      "Epoch: 142, Loss: 0.000006\n",
      "Epoch: 143, Loss: 0.000006\n",
      "Epoch: 144, Loss: 0.000006\n",
      "Epoch: 145, Loss: 0.000006\n",
      "Epoch: 146, Loss: 0.000006\n",
      "Epoch: 147, Loss: 0.000006\n",
      "Epoch: 148, Loss: 0.000006\n",
      "Epoch: 149, Loss: 0.000006\n",
      "Epoch: 150, Loss: 0.000005\n",
      "Epoch: 151, Loss: 0.000006\n",
      "Epoch: 152, Loss: 0.000005\n",
      "Epoch: 153, Loss: 0.000006\n",
      "Epoch: 154, Loss: 0.000005\n",
      "Epoch: 155, Loss: 0.000005\n",
      "Epoch: 156, Loss: 0.000005\n",
      "Epoch: 157, Loss: 0.000005\n",
      "Epoch: 158, Loss: 0.000005\n",
      "Epoch: 159, Loss: 0.000005\n",
      "Epoch: 160, Loss: 0.000005\n",
      "Epoch: 161, Loss: 0.000005\n",
      "Epoch: 162, Loss: 0.000005\n",
      "Epoch: 163, Loss: 0.000005\n",
      "Epoch: 164, Loss: 0.000005\n",
      "Epoch: 165, Loss: 0.000005\n",
      "Epoch: 166, Loss: 0.000005\n",
      "Epoch: 167, Loss: 0.000005\n",
      "Epoch: 168, Loss: 0.000005\n",
      "Epoch: 169, Loss: 0.000005\n",
      "Epoch: 170, Loss: 0.000005\n",
      "Epoch: 171, Loss: 0.000005\n",
      "Epoch: 172, Loss: 0.000005\n",
      "Epoch: 173, Loss: 0.000005\n",
      "Epoch: 174, Loss: 0.000005\n",
      "Epoch: 175, Loss: 0.000005\n",
      "Epoch: 176, Loss: 0.000005\n",
      "Epoch: 177, Loss: 0.000005\n",
      "Epoch: 178, Loss: 0.000005\n",
      "Epoch: 179, Loss: 0.000005\n",
      "Epoch: 180, Loss: 0.000005\n",
      "Epoch: 181, Loss: 0.000005\n",
      "Epoch: 182, Loss: 0.000005\n",
      "Epoch: 183, Loss: 0.000005\n",
      "Epoch: 184, Loss: 0.000005\n",
      "Epoch: 185, Loss: 0.000005\n",
      "Epoch: 186, Loss: 0.000005\n",
      "Epoch: 187, Loss: 0.000005\n",
      "Epoch: 188, Loss: 0.000005\n",
      "Epoch: 189, Loss: 0.000005\n",
      "Epoch: 190, Loss: 0.000005\n",
      "Epoch: 191, Loss: 0.000005\n",
      "Epoch: 192, Loss: 0.000005\n",
      "Epoch: 193, Loss: 0.000005\n",
      "Epoch: 194, Loss: 0.000005\n",
      "Epoch: 195, Loss: 0.000005\n",
      "Epoch: 196, Loss: 0.000005\n",
      "Epoch: 197, Loss: 0.000005\n",
      "Epoch: 198, Loss: 0.000005\n",
      "Epoch: 199, Loss: 0.000005\n",
      "388.86339235305786\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "print(torch.cuda.is_available())\n",
    "import time\n",
    "device = torch.device('cuda:0')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "#model = nn.Sequential(nn.Linear(4, 512), nn.Tanh(), nn.Linear(512, 256), nn.Tanh(), nn.Linear(256, 1))\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 200\n",
    "\n",
    "start = time.time()\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for X, y in train_loader:\n",
    "        train_d = X.to(device)\n",
    "        train_d_c = y.to(device)\n",
    "\n",
    "        outputs = model(train_d)\n",
    "        loss = loss_fn(outputs, train_d_c)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e830e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.4290, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    k = 0\n",
    "    ttl = 0\n",
    "    for X, y in test_loader:\n",
    "        val_d = X.to(device) \n",
    "        val_d_c = y.to(device)\n",
    "\n",
    "        outputs = model(val_d)\n",
    "        \n",
    "        \n",
    "      \n",
    "        for i in range(len(outputs)):\n",
    "            #print(outputs[i]/val_d_c[i])\n",
    "            #print(\"\\n\")\n",
    "            out = (outputs[i]-1) * (max_val-min_val) + max_val\n",
    "            #print(out)\n",
    "            val = (val_d_c[i]-1) * (max_val-min_val) + max_val\n",
    "            #print(val)\n",
    "            #print(\"\\n\")\n",
    "            ttl += (1 - abs(out-val)/val) * 100\n",
    "            #calc absolute diff divide by ground truth\n",
    "            k+=1\n",
    "    print(ttl/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260aed04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437f059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539e68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
